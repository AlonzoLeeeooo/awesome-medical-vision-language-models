[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://GitHub.com/Naereen/StrapDown.js/graphs/commit-activity)
[![PR's Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat)](http://makeapullrequest.com) 
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

<!-- <hr /> -->

# <p align=center>`Awesome Medical Vison-Language Models`</p>

A curated list of awesome resources in medical vision-language models (**in chronological order**), inspired by the other awesome-initiatives. 

[An awesome list](https://github.com/zhjohnchan/awesome-vision-and-language-pretraining) on general vision-language pre-training.

<!-- We intend to regularly update the relevant latest papers and their open-source implementations on this page. If you find some overlooked papers, please open an issue or contact at fahad.shamshad3@gmail.com. -->

## Overview
- [Survey Papers](#survey)
- [Medical Vision-Language Pre-Training](#medical-vision-language-pre-training)
- [Vision-Language Models for Healthcare](#vision-language-models-for-healthcare)
- [Datasets](#datasets)
<!-- - [General Vision-Language Models](#general-vision-language-models) -->
<!-- - [Medical Image Reconstruction](#reconstruction) -->

# Survey

**Beyond Medical Imaging: A Review of Multimodal Deep Learning in Radiology.** [Apr., 2022].<br>
*Lars HeiligerLars Heiliger, Anjany Sekuboyina, Bjoern Menze, Jan EggerJan Egger, Jens Kleesiek.*<br>
[[PDF](https://www.researchgate.net/profile/Jan-Egger-2/publication/358581125_Beyond_Medical_Imaging_A_Review_of_Multimodal_Deep_Learning_in_Radiology/links/620a1e5a7b05f82592ea5bda/Beyond-Medical-Imaging-A-Review-of-Multimodal-Deep-Learning-in-Radiology.pdf)] 

# Medical Vision-Language Pre-Training

  **Self-supervised Image-text Pre-training With Mixed Data In Chest X-rays.** [Mar., 2021].<br>
*Xiaosong Wang, Ziyue Xu, Leo Tam, Dong Yang, Daguang Xu.*<br>
 [[PDF](https://arxiv.org/pdf/2103.16022)] 
 
  **MMBERT: Multimodal BERT Pretraining for Improved Medical VQA.** (Short Paper) [Apr., 2021].<br>
*Yash Khare, Viraj Bagal, Minesh Mathew, Adithi Devi, U Deva Priyakumar, CV Jawahar.*<br>
 [[PDF](https://arxiv.org/abs/2104.01394)] [[Github](https://github.com/VirajBagal/MMBERT)]

  **Multi-modal Understanding and Generation for Medical Images and Text via Vision-Language Pre-Training.** [May, 2021] [JBHI 2022].<br>
*Jong Hak Moon, Hyungyung Lee, Woncheol Shin, Young-Hak Kim, Edward Choi.*<br>
 [[PDF](https://arxiv.org/abs/2105.11333)] [[Github](https://github.com/SuperSupermoon/MedViLL)]
 
  **Generalized radiograph representation learning via cross-supervision between images and free-text radiology reports.** [Oct., 2021] [Nature Machine Learning 2022].<br>
*Hong-Yu Zhou, Xiaoyu Chen, Yinghao Zhang, Ruibang Luo, Liansheng Wang, Yizhou Yu.*<br>
 [[PDF](https://www.nature.com/articles/s42256-021-00425-9)] [[Github](https://github.com/funnyzhou/refers)]

  **Clinical-BERT: Vision-Language Pre-training for Radiograph Diagnosis and Reports Generation.** [Jun., 2022] [AAAI 2022].<br>
*Bin Yan, Mingtao Pei.*<br>
 [[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/20204)] 

  **Vision-Language Pretraining Enables Radiographs and Reports to be Learned without Curation.** [Aug., 2022].<br>
*Sangjoon Park, Eun Sun Lee, Jeong Eun Lee, Jong Chul Ye.*<br>
 [[PDF](https://arxiv.org/abs/2208.05140)]
 
  **Multi-Modal Masked Autoencoders for Medical Vision-and-Language Pre-Training.** [Sep., 2022] [MICAI 2022].<br>
*Zhihong Chen, Yuhao Du, Jinpeng Hu, Yang Liu, Guanbin Li, Xiang Wan, Tsung-Hui Chang.*<br>
 [[PDF](https://arxiv.org/abs/2209.07098)] [[Github](https://github.com/zhjohnchan/M3AE)]
 
  **Align, Reason and Learn: Enhancing Medical Vision-and-Language Pre-training with Knowledge.** [Sep., 2022] [ACM MM 2022].<br>
*Zhihong Chen, Guanbin Li, Xiang Wan.*<br>
 [[PDF](https://arxiv.org/abs/2209.07118)] [[Github](https://github.com/zhjohnchan/ARL)]
 
  **Medical Image Understanding with Pretrained Vision Language Models: A Comprehensive Study.** [Sep., 2022].<br>
*Ziyuan Qin, Huahui Yi, Qicheng Lao, Kang Li.*<br>
 [[PDF](https://arxiv.org/abs/2209.15517)]
 
  **Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning.** [Sep., 2022] [Nature Biomedical Engineering 2022].<br>
*Ekin Tiu, Ellie Talius, Pujan Patel, Curtis P. Langlotz, Andrew Y. Ng, Pranav Rajpurkar.*<br>
 [[PDF](https://www.nature.com/articles/s41551-022-00936-9)] [[Github](https://github.com/rajpurkarlab/CheXzero)]
 

# Vision-Language Models for Healthcare

## Classification

   **BERTHop: An Effective Vision-and-Language Model for Chest X-ray Disease Diagnosis.** [Aug., 2021] [ICCV Workshop 2021].<br>
*Masoud Monajatipoor, Mozhdeh Rouhsedaghat, Liunian Harold Li, Aichi Chien, C.-C. Jay Kuo, Fabien Scalzo, Kai-Wei Chang.*<br>
 [[PDF](https://arxiv.org/abs/2108.04938)] 
 
## Medical Vision Question Answering

   **A Comparison of Pre-trained Vision-and-Language Models for Multimodal Representation Learning across Medical Images and Reports.** [Sep., 2020] [BIBM, 2020].<br>
*Yikuan Li, Hanyin Wang, Yuan Luo.*<br>
 [[PDF](https://arxiv.org/abs/2009.01523)] [[Github](https://github.com/YIKUAN8/Transformers-VQA)]
 
   **AMAM: An Attention-based Multimodal Alignment Model for Medical Visual Question Answering.** [Sep., 2022] [KBS, 2022].<br>
*Haiwei Pan, Shuning He, Kejia Zhang, Bo Qu, Chunling Chen, Kun Shi.*<br>
 [[PDF](https://doi.org/10.1016/j.knosys.2022.109763)] 
 
   **MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering.** [Jul., 2021].<br>
*Haiwei Pan, Shuning He, Kejia Zhang, Bo Qu, Chunling Chen, Kun Shi.*<br>
 [[PDF](https://arxiv.org/abs/2107.03216)] 

## Medical Object Locolization and Anomaly Detection

   **Weakly supervised one-stage vision and language disease detection using large scale pneumonia and pneumothorax studies.** [Jul., 2020] [MICAI, 2020].<br>
*Leo K. Tam, Xiaosong Wang, Evrim Turkbey, Kevin Lu, Yuhong Wen, Daguang Xu.*<br>
 [[PDF](https://arxiv.org/abs/2007.15778)] 

   **Adapting Pretrained Vision-Language Foundational Models to Medical Imaging Domains.** [Oct., 2022].<br>
*Pierre Chambon, Christian Bluethgen, Curtis P. Langlotz, Akshay Chaudhari.*<br>
 [[PDF](https://arxiv.org/abs/2210.04133)] 

## Medical Image Segmentation

   **LViT: Language meets Vision Transformer in Medical Image Segmentation.** [Jun., 2022].<br>
*Zihan Li, Yunxiang Li, Qingde Li, Puyang Wang, You Zhang, Dazhou Guo, Le Lu, Dakai Jin, Qingqi Hong.*<br>
 [[PDF](https://arxiv.org/abs/2206.14718)] [[Github](https://github.com/HUANGLIZI/LViT)]

## Clinical Report Generation

   **Retrieval-Based Chest X-Ray Report Generation Using a Pre-trained Contrastive Language-Image Model.** [Nov., 2021] [ML4H 2021].<br>
*Mark Endo, Rayan Krishnan, Viswesh Krishna, Andrew Y. Ng, Pranav Rajpurkar.*<br>
 [[PDF](https://proceedings.mlr.press/v158/endo21a.html)] [[Github](https://github.com/rajpurkarlab/CXR-RePaiR)]

   **Auto-Encoding Knowledge Graph for Unsupervised Medical Report Generation.** [Nov., 2021] [NeurIPS 2021].<br>
*Fenglin Liu, Chenyu You, Xian Wu, Shen Ge, Sheng Wang, Xu Sun.*<br>
 [[PDF](https://arxiv.org/abs/2111.04318)] 
 
   **RepsNet: Combining Vision with Language for Automated Medical Reports.** [Sep., 2022] [MICAI 2022].<br>
*Ajay Kumar Tanwani, Joelle Barral, Daniel Freedman.*<br>
 [[PDF](https://arxiv.org/abs/2209.13171)] 

# Explaination, Bias, and Robustness

# Datasets

   **MIMIC-CXR-JPG, a large publicly available database of labeled chest radiographs.** [Jan., 2019].<br>
*Alistair E. W. Johnson, Tom J. Pollard, Nathaniel R. Greenbaum, Matthew P. Lungren, Chih-ying Deng, Yifan Peng, Zhiyong Lu, Roger G. Mark, Seth J. Berkowitz, Steven Horng.*<br>
 [[PDF](https://arxiv.org/pdf/1901.07042.pdf)] [[Url](https://doi.org/10.13026/8360-t248)]
 
   **MIMIC-CXR-annotations.** [Jul, 2020].<br>
*Leo K. Tam, Xiaosong Wang, Evrim Turkbey, Kevin Lu, Yuhong Wen, Daguang Xu.*<br>
 [[PDF](https://arxiv.org/abs/2007.15778)] [[Github](https://github.com/leotam/MIMIC-CXR-annotations)]

   **RadGraph: Extracting Clinical Entities and Relations from Radiology Reports.** [Jun, 2021] [NeurIPS 2021].<br>
*Saahil Jain, Ashwin Agrawal, Adriel Saporta, Steven QH Truong, Du Nguyen Duong, Tan Bui, Pierre Chambon, Yuhao Zhang, Matthew P. Lungren, Andrew Y. Ng, Curtis P. Langlotz, Pranav Rajpurkar.*<br>
 [[PDF](https://arxiv.org/abs/2106.14463)] [[Url](https://physionet.org/content/radgraph/1.0.0/)]
